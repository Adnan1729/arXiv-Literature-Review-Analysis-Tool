{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arxiv pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY = '((ti:Bayesian OR abs:Bayesian OR ti:\"Uncertainty Quantification\" OR abs:\"Uncertainty Quantification\" OR ti:UQ OR abs:UQ) AND (all:Modular OR all:\"Multi-Fidelity\" OR all:\"Real-Time\" OR all:\"Digital Twin\"))'\n",
    "MAX_RESULTS = 10000 # Limit the number of papers to analyze for a quick look"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6e20a",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78531787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_theme_name(theme_key):\n",
    "    \"\"\"Converts a theme key (e.g., 'T_Digital_Twins') into a clean display name (e.g., 'Digital Twins').\"\"\"\n",
    "    # Split by the first underscore (to remove T_ or M_) and then replace remaining underscores with spaces\n",
    "    parts = theme_key.split('_', 1)\n",
    "    if len(parts) > 1:\n",
    "        return parts[1].replace('_', ' ').title()\n",
    "    return theme_key.replace('_', ' ').title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac636",
   "metadata": {},
   "source": [
    "## Data Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442926d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_arxiv_papers(query, max_results):\n",
    "    \"\"\"\n",
    "    Fetches papers from arXiv based on a structured query.\n",
    "    Note: Requires the 'arxiv' Python package (pip install arxiv).\n",
    "    \"\"\"\n",
    "    print(f\"Searching arXiv for: '{query}'\")\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Configure the search parameters\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "        sort_order=arxiv.SortOrder.Descending # Start with the newest papers\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    # Use a try-except block for robust API call handling\n",
    "    try:\n",
    "        for r in client.results(search):\n",
    "            results.append({\n",
    "                'title': r.title.replace('\\n', ' ').strip(),\n",
    "                'abstract': r.summary.replace('\\n', ' ').strip(),\n",
    "                'year': r.published.year,\n",
    "                'primary_category': r.primary_category,\n",
    "                'categories': [c for c in r.categories if c.startswith('cs.') or c.startswith('stat.')], # Filter to ML/CS categories\n",
    "                'authors': [a.name for a in r.authors],\n",
    "                'url': r.entry_id,\n",
    "            })\n",
    "        print(f\"Successfully fetched {len(results)} papers.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data from arXiv: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a299843",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ba59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_analysis(df):\n",
    "    \"\"\"Analyzes the publication trends over time.\"\"\"\n",
    "    print(\"\\n--- 1. TEMPORAL ANALYSIS (Publication Trends) ---\")\n",
    "\n",
    "    # Count papers per year\n",
    "    year_counts = df['year'].value_counts().sort_index()\n",
    "    print(\"Papers Published Per Year:\")\n",
    "    print(year_counts)\n",
    "\n",
    "    # Plotting the trend\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    year_counts.plot(kind='bar', color='#1f77b4')\n",
    "    plt.title(f'Temporal Trend of Relevant Papers (N={len(df)})')\n",
    "    plt.xlabel('Publication Year')\n",
    "    plt.ylabel('Number of Papers')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def bibliometric_analysis(df):\n",
    "    \"\"\"Identifies top categories (authors removed per user request).\"\"\"\n",
    "    print(\"\\n--- 2. BIBLIOMETRIC ANALYSIS (Key Domains) ---\")\n",
    "\n",
    "    # Top Categories\n",
    "    all_categories = df['categories'].explode()\n",
    "    top_categories = all_categories.value_counts().head(10)\n",
    "    print(\"\\nTop 10 Most Frequent Categories (Research Domains):\")\n",
    "    print(top_categories)\n",
    "\n",
    "def thematic_analysis(df):\n",
    "    \"\"\"Categorizes papers based on thematic and methodological keywords and plots the distribution.\"\"\"\n",
    "    # Define keywords for the themes based on your review plan\n",
    "    themes = {\n",
    "        'T_Digital_Twins': ['digital twin', 'physical system', 'virtual representation'],\n",
    "        'T_Real_Time_Systems': ['real-time', 'online execution', 'dynamic modeling', 'low latency'],\n",
    "        'M_Modular_Frameworks': ['modular', 'decentralized', 'decoupled', 'component-based'],\n",
    "        'M_Multi_Source_Data': ['multi-fidelity', 'multi-source', 'heterogeneous data', 'information fusion'],\n",
    "        'M_Uncertainty_Quantification': ['uncertainty quantification', 'uq', 'bayesian inference', 'credible interval'],\n",
    "        'M_Surrogate_Modeling': ['emulator', 'surrogate model', 'reduced order model', 'rom']\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- 3. THEMATIC & METHODOLOGICAL ANALYSIS ---\")\n",
    "\n",
    "    # Create a column for each theme (True/False if keyword found in title/abstract)\n",
    "    df_temp = df.copy()\n",
    "    for theme, keywords in themes.items():\n",
    "        # Combine title and abstract for comprehensive search\n",
    "        text_to_search = (df_temp['title'] + ' ' + df_temp['abstract']).str.lower()\n",
    "\n",
    "        # Check if any keyword in the list is present\n",
    "        # Note: Using regex '|' for OR condition between keywords\n",
    "        pattern = '|'.join(keywords)\n",
    "        df_temp[theme] = text_to_search.str.contains(pattern, na=False)\n",
    "\n",
    "    # Summarize the thematic counts\n",
    "    theme_summary = df_temp[themes.keys()].sum().sort_values(ascending=False)\n",
    "    print(\"Keyword-Based Thematic Counts:\")\n",
    "    print(theme_summary)\n",
    "\n",
    "    # --- Plotting the thematic summary (Infographic 1) ---\n",
    "\n",
    "    # Map the internal theme keys to clean display names for the plot\n",
    "    clean_summary = theme_summary.rename(clean_theme_name)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    clean_summary.plot(kind='barh', color='#ff7f0e') # Horizontal bar chart for better readability\n",
    "    plt.title('Relative Dominance of Thematic Keywords in Paper Abstracts')\n",
    "    plt.xlabel('Number of Papers Mentioning Keyword(s)')\n",
    "    plt.ylabel('Thematic Category')\n",
    "    plt.gca().invert_yaxis() # Put the highest count at the top\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # Identify the top 5 papers for the most dominant theme (for quick review)\n",
    "    dominant_theme = theme_summary.index[0]\n",
    "    print(f\"\\nTop 5 papers for the most dominant theme ('{clean_theme_name(dominant_theme)}'):\")\n",
    "    top_papers = df_temp[df_temp[dominant_theme]].head(5)\n",
    "\n",
    "    for index, row in top_papers.iterrows():\n",
    "        print(f\"  - Title: {row['title']}\")\n",
    "        print(f\"    URL: {row['url']}\")\n",
    "        print(f\"    Year: {row['year']}, Primary Category: {row['primary_category']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return df_temp # Return the dataframe with theme flags for co-occurrence analysis\n",
    "\n",
    "def temporal_thematic_evolution(df_with_themes):\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes how the thematic focus of the papers has changed over time\n",
    "    using a multi-line chart (Infographic 3).\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 4. TEMPORAL THEMATIC EVOLUTION (Trend Infographic) ---\")\n",
    "\n",
    "    # Identify themes for grouping\n",
    "    themes = [col for col in df_with_themes.columns if col.startswith(('T_', 'M_'))]\n",
    "\n",
    "    # Group by year and sum the boolean theme flags\n",
    "    temporal_theme_counts = df_with_themes.groupby('year')[themes].sum()\n",
    "\n",
    "    # Rename columns for the plot\n",
    "    temporal_theme_counts.columns = [clean_theme_name(t) for t in temporal_theme_counts.columns]\n",
    "\n",
    "    print(\"Temporal Theme Counts by Year:\")\n",
    "    print(temporal_theme_counts)\n",
    "\n",
    "    # Plotting the Line Chart (Infographic 3)\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Filter out years with very few papers for cleaner trend lines, e.g., before 2010\n",
    "    start_year = temporal_theme_counts[temporal_theme_counts.sum(axis=1) > 10].index.min()\n",
    "    if pd.isna(start_year):\n",
    "        start_year = temporal_theme_counts.index.min()\n",
    "\n",
    "    # Plot the line chart\n",
    "    temporal_theme_counts.loc[start_year:].plot(kind='line', marker='o', linewidth=2, figsize=(12, 7))\n",
    "\n",
    "    plt.title('Evolution of Thematic Focus Over Time (Yearly Paper Counts)')\n",
    "    plt.xlabel(f'Publication Year (Showing data from {int(start_year)} onwards)')\n",
    "    plt.ylabel('Number of Papers Mentioning Theme')\n",
    "    plt.legend(title='Thematic Category', loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout for legend\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def category_thematic_co_occurrence(df_with_themes):\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes the co-occurrence between major arXiv categories\n",
    "    and the predefined thematic keywords using a heatmap (Infographic 4).\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 5. DOMAIN-THEME CO-OCCURRENCE ANALYSIS (Clustering Infographic) ---\")\n",
    "\n",
    "    # Explode categories to one row per paper-category pair\n",
    "    df_exploded = df_with_themes.explode('categories')\n",
    "\n",
    "    # Identify themes for grouping\n",
    "    themes = [col for col in df_exploded.columns if col.startswith(('T_', 'M_'))]\n",
    "\n",
    "    # Filter to only the top categories (e.g., those with at least 50 papers) for clarity in the plot\n",
    "    min_cat_count = 50\n",
    "    valid_categories = df_exploded['categories'].value_counts()\n",
    "    valid_categories = valid_categories[valid_categories >= min_cat_count].index\n",
    "    df_filtered = df_exploded[df_exploded['categories'].isin(valid_categories)]\n",
    "\n",
    "    if df_filtered.empty or not themes:\n",
    "        print(\"Not enough data or themes to generate co-occurrence matrix after filtering.\")\n",
    "        return\n",
    "\n",
    "    # Calculate the co-occurrence matrix (Count of papers in Category X that also match Theme Y)\n",
    "    # The sum() operation counts the True (1) values for each theme within each category group.\n",
    "    co_occurrence_matrix = df_filtered.groupby('categories')[themes].sum()\n",
    "\n",
    "    print(f\"Co-occurrence Matrix (Filtered Categories with >={min_cat_count} papers):\")\n",
    "    print(co_occurrence_matrix)\n",
    "\n",
    "    # --- Plotting the Heatmap (Infographic 4) ---\n",
    "    # Generate clean labels for the x-axis\n",
    "    clean_themes = [clean_theme_name(t) for t in themes]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(co_occurrence_matrix, aspect='auto', cmap='viridis')\n",
    "\n",
    "    # Setup labels\n",
    "    plt.colorbar(label='Number of Co-occurring Papers')\n",
    "    plt.xticks(range(len(themes)), clean_themes, rotation=45, ha='right')\n",
    "    plt.yticks(range(len(valid_categories)), valid_categories)\n",
    "\n",
    "    plt.title('Heatmap of Thematic Keyword Co-occurrence by Research Domain')\n",
    "    plt.xlabel('Thematic Keyword (Methodology/Application)')\n",
    "    plt.ylabel('arXiv Research Domain Category')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0a909",
   "metadata": {},
   "source": [
    "## Main Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the analysis.\"\"\"\n",
    "    print(\"--- arXiv Literature Review Analysis ---\")\n",
    "    print(f\"Attempting to fetch up to {MAX_RESULTS} papers.\")\n",
    "\n",
    "    # 1. Fetch Data\n",
    "    df_papers = fetch_arxiv_papers(SEARCH_QUERY, MAX_RESULTS)\n",
    "\n",
    "    if df_papers.empty:\n",
    "        print(\"\\nAnalysis failed: No data was fetched. Please check your network connection or the search query.\")\n",
    "        return\n",
    "\n",
    "    # 2. Bibliometric & Temporal Analysis\n",
    "    temporal_analysis(df_papers)\n",
    "    bibliometric_analysis(df_papers)\n",
    "\n",
    "    # 3. Thematic & Methodological Analysis (Returns the dataframe with theme flags)\n",
    "    df_with_themes = thematic_analysis(df_papers)\n",
    "\n",
    "    # 4. New Temporal Thematic Evolution Analysis\n",
    "    temporal_thematic_evolution(df_with_themes)\n",
    "\n",
    "    # 5. Domain-Theme Co-occurrence Analysis\n",
    "    category_thematic_co_occurrence(df_with_themes)\n",
    "\n",
    "    # 6. Limitation Note\n",
    "    print(\"\\n--- NOTE ON GEOGRAPHICAL ANALYSIS ---\")\n",
    "    print(\"The arXiv API does not provide author affiliation or country information,\")\n",
    "    print(\"so a 'Papers by Country' infographic cannot be generated using this data source.\")\n",
    "    print(\"The Category-Theme Co-occurrence map serves as a proxy for Domain Clustering.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have the necessary libraries installed:\n",
    "    # pip install arxiv pandas matplotlib\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
